## 1. 우리가 겪는 Confluence 검색의 한계

### 😤 현실적인 문제들

#### 문제 1: 키워드 불일치
```
내가 찾고 싶은 것: "매출 현황"
실제 문서 제목들:
- "Revenue Dashboard Q3"
- "Sales Performance Analysis" 
- "수익 분석 리포트"

→ Confluence 검색: 결과 없음 😭
```

#### 문제 1: 키워드 불일치
```
내가 찾고 싶은 것: "신입사원 교육"
실제 문서 제목들:
- "Onboarding Process Guide"
- "New Employee Training Manual" 
- "입사자 오리엔테이션 자료"

→ Confluence 검색: 결과 없음 😭
```

#### 문제 2: 팀별 용어 차이
```
같은 내용, 다른 표현:
• 개발팀: "Sprint Retrospective"
• 기획팀: "프로젝트 회고"  
• 마케팅팀: "캠페인 결과 분석"

모두 "프로젝트 결과"를 다루지만 검색어가 달라서 못 찾음
```

#### 문제 3: 추상적 질문
```
내 궁금증: "우리 회사 휴가 정책이 어떻게 바뀌었지?"

Confluence에서 필요한 검색어:
- "휴가", "연차", "병가", "특별휴가"
- "인사규정", "복리후생", "근무제도"

→ 여러 번 검색해야 하고, 놓치는 정보 많음
```

#### 문제 4: 맥락 이해 불가
```
질문: "지난번 회의에서 결정된 사항이 뭐였지?"

Confluence는 몰라요:
- 언제가 "지난번"인지
- 어떤 회의인지  
- 누가 참석했는지

→ 검색 자체가 불가능
```# RAG 시스템의 LLM
**RAG의 생성 엔진과 추론 두뇌**

김상훈 | 2025.07.17

---

## 시작하며

안녕하세요! 오늘 첫 번째 발표를 맡게 된 김상훈입니다.

### 🎯 우리 AI 스터디의 목표
앞서 소개해드린 것처럼, 우리는 **3단계**에 걸쳐 RAG 시스템을 마스터할 예정입니다:
- **1단계**: LangChain 기반 기본 RAG 구축 ← **현재 여기**
- **2단계**: LangGraph로 Agent 기반 고성능 RAG
- **3단계**: Neo4J로 지식 그래프 기반 RAG

### 📚 오늘 우리가 다룰 내용
저는 **LLM(Large Language Model)** 파트를 맡았습니다. RAG 시스템에서 LLM은 **"두뇌"** 역할을 합니다.

### 🤔 그런데 왜 하필 RAG인가?

**혹시 이런 경험 있으신가요?**
- Confluence에서 "지난 달 매출 보고서" 검색했는데 안 나옴 😭
- 실제로는 "Q3 Revenue Analysis"라는 제목으로 저장되어 있었음
- 또는 "예산" 검색했는데, 재무팀은 "Budget", 기획팀은 "Plan"이라고 써놨음

**바로 이 문제를 해결하기 위해** RAG 시스템을 도입하려고 합니다!

### 🎯 최종 목표
**"작년 프로젝트 결과 어땠지?"**라고 자연스럽게 물어봤을 때, Confluence 전체를 뒤져서 관련 문서들을 찾아내고 **종합적인 답변**을 주는 시스템 구축

---

## RAG 시스템 전체 구조

### 🧩 RAG의 핵심 구성요소들
```
사용자 질문 → [1.임베딩] → [2.벡터검색] → [3.문서검색] → [4.LLM] → 답변
```

오늘부터 각자 담당 영역을 차례로 발표할 예정입니다:

| 순서 | 담당자 | 영역 | 역할 |
|------|--------|------|------|
| **1주차** | **김상훈** | **LLM** | 검색된 문서를 읽고 답변 생성 |
| 2주차 | 이우성 | Data Chunking | 문서를 적절한 크기로 분할 |
| 3주차 | 박민석 | Embedding | 텍스트를 벡터로 변환 |
| 4주차 | 구태호 | Vector Database | 벡터 저장 및 유사도 검색 |
| 5주차 | 김우재, 김삼진 | LangChain | 전체 파이프라인 연결 |

### 🎭 LLM의 역할 (오늘의 주제)
RAG에서 LLM은 **"마지막 단계의 두뇌"**입니다:
- 검색된 여러 문서를 **종합 이해**
- 사용자 질문에 **정확히 답변**
- **자연스러운 한국어**로 설명

---

## 2. RAG가 이를 어떻게 해결하는가?

### RAG = 똑똑한 사내 검색 엔진
**RAG = 의미 기반 검색(Retrieval) + AI 답변 생성(Generation)**

기존 Confluence: "신입사원 교육" 검색 → 제목에 정확히 포함된 문서만  
**RAG**: "신입사원 교육" 검색 → 의미가 비슷한 모든 문서 찾기 → **AI가 읽고 종합해서 답변**

### RAG 파이프라인
```
사용자 질문 → 의미 기반 문서 검색 → [관련 문서들 + 질문] → LLM → 통합 답변
```

### 실제 해결 과정

#### ✅ 문제 1 해결: 의미 기반 검색
```
질문: "신입사원 교육 어떻게 하나요?"

RAG가 찾아내는 문서들:
📄 "Onboarding Process Guide" ✓
📄 "New Employee Training Manual" ✓
📄 "입사자 오리엔테이션 자료" ✓
📄 "첫 출근 준비사항" ✓

→ 제목은 다르지만 의미가 비슷한 문서들을 모두 발견!
```

#### ✅ 문제 2 해결: 통합 이해
```
질문: "프로젝트 회고 결과가 어땠나요?"

RAG가 찾은 문서들:
📄 개발팀 "Sprint Retrospective" 
📄 기획팀 "프로젝트 회고"
📄 마케팅팀 "캠페인 결과 분석"

LLM이 통합해서 답변:
"각 팀의 회고 결과를 종합하면, 개발팀은 코드 리뷰 프로세스 개선,
기획팀은 요구사항 명확화, 마케팅팀은 타겟 세분화가 
주요 개선사항으로 도출되었습니다."
```

#### ✅ 문제 3 해결: 맥락 이해
```
질문: "우리 회사 휴가 정책이 어떻게 바뀌었지?"

RAG 처리:
1. "휴가", "연차", "정책", "변경" 관련 문서 모두 검색
2. 시간순으로 정리
3. 변경사항만 추출해서 답변

"2024년부터 리프레시 휴가 3일 추가, 
경조사휴가 범위 확대, 
반차 단위 사용 가능으로 변경되었습니다."
```

---

## 3. LLM은 어떻게 동작하는가?

### 쉽게 말하면: 거대한 "패턴 인식 기계"
LLM은 수십억 개의 텍스트를 학습해서 **"이런 질문에는 보통 이렇게 답한다"**는 패턴을 익힌 AI입니다.

### 핵심 메커니즘: Attention (주의집중)

#### 사람이 글을 읽을 때
```
"김대리가 작성한 보고서에 따르면 매출이 증가했다"

우리 뇌: "김대리가" → "보고서" → "매출 증가" 연결해서 이해
```

#### LLM의 Attention도 비슷함
```python
# LLM 내부에서 일어나는 일 (의사코드)
for word in sentence:
    attention_scores = calculate_importance(word, other_words)
    # "김대리" - "보고서" 연관도: 0.8
    # "보고서" - "매출" 연관도: 0.9
```

### RAG에서 중요한 개념: Context Window

#### Context Window란?
- LLM이 **한 번에 기억할 수 있는 글자 수**
- 검색해온 문서 + 질문이 모두 이 안에 들어가야 함

#### 모델별 Context Window 크기
```
GPT-4: 약 50만 글자 (A4 250페이지)
Claude-3: 약 80만 글자 (A4 400페이지)  
Gemini 1.5: 약 400만 글자 (A4 2000페이지)
```

#### 우리 사내 검색 시스템에서는?
```
Confluence 문서 평균 20페이지 + 사용자 질문 = 약 4만 글자
→ 대부분의 LLM으로 처리 가능 ✅
```

---

## 4. 어떤 LLM을 선택해야 할까?

### 선택 기준 3가지

#### 1. 📖 독해력 (얼마나 잘 이해하는가?)
```
테스트: 회의록 3개, 기획서 2개 주고 "프로젝트 진행상황은?"

좋은 LLM: "프로젝트 A는 개발 완료, 프로젝트 B는 기획 단계이며,
          주요 이슈는 리소스 부족입니다."
나쁜 LLM: "문서에 프로젝트라고 써있네요" (표면적 이해만)
```

#### 2. 🔍 사실 확인 능력 (헛소리 안 하기)
```
주어진 문서: "김대리가 마케팅팀 팀장으로 승진"
질문: "김대리 연봉은 얼마인가요?"

좋은 LLM: "연봉 정보는 제공된 문서에서 확인할 수 없습니다."
나쁜 LLM: "김대리 연봉은 5000만원입니다" (추측으로 답변 😱)
```

#### 3. ⚡ 속도와 비용
- **속도**: 사용자가 답변 기다리는 시간
- **비용**: API 호출 비용 (토큰당 요금)

### 주요 모델 비교

| 모델 | 독해력 | 사실확인 | 속도 | 비용 | 우리팀 추천도 |
|------|--------|----------|------|------|---------------|
| **GPT-4o** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐ | 높음 | 🥈 프로토타입용 |
| **Claude-3.5** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ | 중간 | 🥇 **최적** |
| **Llama 3.1** | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ | 낮음 | 🥉 비용절약용 |

### 우리 사내 검색 시스템에는?
**Claude-3.5 Sonnet 추천!**
- 긴 문서 이해력 우수 (다양한 팀 문서 형식 대응)
- 헛소리 적음 (중요한 회사 정보니까)
- 적당한 속도와 비용

---

## 5. LLM이 정확한 답변을 하게 만드는 방법

### 프롬프트 = LLM에게 주는 작업 지시서
사람한테 일 시킬 때도 명확히 설명해야 하듯이, LLM에게도 **정확한 지시**가 필요합니다.

### 나쁜 프롬프트 vs 좋은 프롬프트

#### ❌ 나쁜 예시
```
"문서 보고 질문에 답해줘"

→ LLM: "뭘 어떻게 답하라는 거지?" 😵‍💫
```

#### ✅ 좋은 예시  
```
당신은 회사 FMS 시스템의 전문 도우미입니다.
주어진 문서를 바탕으로 질문에 답변해주세요.

규칙:
1. 문서에 있는 내용만 사용하세요
2. 확실하지 않으면 "문서에서 확인할 수 없습니다"라고 하세요  
3. 답변 뒤에 참고한 문서명을 적어주세요

문서: [검색된 문서들]
질문: [사용자 질문]
답변:
```

### 실전 프롬프트 템플릿
```python
CONFLUENCE_SEARCH_PROMPT = """
역할: 당신은 우리 회사의 Confluence 문서 전문 도우미입니다.

지시사항:
1. 제공된 Confluence 문서들만을 근거로 답변하세요
2. 날짜나 담당자 정보는 정확히 인용하세요
3. 여러 팀의 정보가 있다면 팀별로 구분해서 설명하세요
4. 불확실한 내용은 추측하지 말고 "추가 확인 필요"라고 하세요
5. 답변 끝에 "참고페이지: [페이지명]"을 추가하세요

문서:
{confluence_documents}

질문: {user_question}

답변:
"""
```

### 고급 기법: Few-Shot (예시 주기)
```
예시 1:
Q: 신입사원 교육은 어떻게 진행되나요?
A: 신입사원 교육은 2주 과정으로 진행됩니다. 
   1주차는 회사 소개 및 업무 프로세스, 2주차는 실무 교육입니다.
   (참고페이지: HR팀 온보딩 가이드)

예시 2:  
Q: 내년 휴가 정책 변경사항은?
A: 2025년 휴가 정책 변경사항은 제공된 문서에서 확인할 수 없습니다.

이제 실제 질문에 답변해주세요:
Q: [실제 사용자 질문]
```

---

## 6. 실제 구현 시 고려사항들

### Confluence 연동 특별 고려사항

#### 1. 권한 관리
```python
# 사용자별 접근 가능한 문서만 검색
def filter_by_permission(documents, user_id):
    accessible_docs = []
    for doc in documents:
        if check_confluence_permission(doc.space, user_id):
            accessible_docs.append(doc)
    return accessible_docs
```

#### 2. 문서 유형별 처리
```python
# Confluence 페이지 타입별 다른 처리
def process_confluence_content(page):
    if page.type == "meeting_notes":
        return extract_action_items(page.content)
    elif page.type == "spec_document":
        return extract_requirements(page.content)
    elif page.type == "report":
        return extract_key_metrics(page.content)
```

#### 3. 실시간 업데이트 반영
- Confluence 페이지 수정 시 자동 재색인
- 삭제된 페이지는 검색 결과에서 제외
- 버전 관리: 최신 버전만 검색 대상

### 품질 보장

#### 1. 응답 검증
```python
def validate_response(context, response):
    checks = {
        'hallucination': detect_hallucination(context, response),
        'completeness': check_completeness(response),
        'relevance': measure_relevance(context, response)
    }
    return all(checks.values())
```

#### 2. A/B 테스팅
- 서로 다른 LLM 모델 비교
- 프롬프트 변형 테스트
- 사용자 만족도 측정

### 비용 최적화

#### 1. 토큰 사용량 모니터링
```python
# 토큰 수 계산
def count_tokens(text, model_name):
    tokenizer = get_tokenizer(model_name)
    return len(tokenizer.encode(text))
```

#### 2. 스마트 라우팅
```python
def route_to_model(query_complexity):
    if complexity < 0.3:
        return "lightweight_model"
    elif complexity < 0.7:
        return "medium_model"
    else:
        return "powerful_model"
```

---

## 실무 체크리스트

### 🔍 모델 선정
- [ ] 컨텍스트 윈도우 크기 확인
- [ ] 도메인별 성능 벤치마크 테스트
- [ ] 비용 대비 성능 분석

### ⚙️ 구현
- [ ] 프롬프트 템플릿 표준화
- [ ] 응답 검증 로직 구현
- [ ] 에러 핸들링 및 폴백 전략

### 📊 모니터링
- [ ] 응답 품질 지표 설정
- [ ] 지연시간 및 처리량 모니터링
- [ ] 비용 추적 시스템 구축

---

## 마무리하며

### 오늘 배운 핵심 내용
1. **RAG에서 LLM = 문서를 읽고 이해해서 친절한 답변을 만드는 역할**
2. **LLM은 거대한 패턴 인식 기계 (Attention 메커니즘)**
3. **우리 FMS 챗봇에는 Claude-3.5 Sonnet이 적합**
4. **좋은 프롬프트 = 명확한 지시서**
5. **실제 구현 시 속도/비용/품질의 밸런스가 중요**

### 다음 단계를 위한 준비
- 이우성님이 발표할 **Data Chunking**과 연결점을 생각해보세요
- "LLM이 이해하기 좋은 문서 조각"을 만드는 게 다음 주제입니다

### 궁금한 점이나 의견이 있다면?
**지금 바로 질문해주세요!** 🙋‍♂️🙋‍♀️

---

## 다음 주 예고
- **이우성님**: Data Chunking 전략과 최적화
- **박민석님**: Embedding 모델 선택과 성능 비교  
- **구태호님**: Vector Database 구축과 검색 최적화